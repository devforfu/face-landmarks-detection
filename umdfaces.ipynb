{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Landmarks\n",
    "\n",
    "Using a subset of [UMD Faces](http://umdfaces.io) database to train a face landmarks predicting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T13:03:14.897395Z",
     "start_time": "2019-01-05T13:03:14.734094Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T13:03:14.910259Z",
     "start_time": "2019-01-05T13:03:14.899361Z"
    }
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "from os.path import join\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "import random\n",
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T13:03:15.039397Z",
     "start_time": "2019-01-05T13:03:15.022253Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    old_path\n",
    "except NameError:\n",
    "    old_path = sys.path\n",
    "    new_path = [str(Path.cwd()/'loop')] + old_path\n",
    "    sys.path = new_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T14:06:05.571940Z",
     "start_time": "2019-01-05T14:06:05.548468Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import PIL.Image\n",
    "from imageio import imread\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.ticker as mtick\n",
    "from pandas_summary import DataFrameSummary\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import models\n",
    "from torchvision.transforms.functional import to_tensor, normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T13:03:15.912311Z",
     "start_time": "2019-01-05T13:03:15.843637Z"
    }
   },
   "outputs": [],
   "source": [
    "import loop\n",
    "from loop import callbacks as C\n",
    "from loop.config import defaults\n",
    "from loop.optimizers import AdamW\n",
    "from loop.torch_helpers.modules import Flatten\n",
    "from loop.training import make_phases, find_lr\n",
    "from loop.torch_helpers.modules import Classifier\n",
    "from loop.schedule import OneCycleSchedule, CosineAnnealingSchedule\n",
    "from basedir import DATA, META, CROPPED, NUM_LANDMARKS\n",
    "from plot import plot_loss_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T13:03:15.931458Z",
     "start_time": "2019-01-05T13:03:15.914127Z"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "DEVICE = torch.device('cuda:1')\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "defaults.device = DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Dataset First Glance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T13:03:16.767897Z",
     "start_time": "2019-01-05T13:03:15.933358Z"
    }
   },
   "outputs": [],
   "source": [
    "meta = pd.read_csv(META)\n",
    "meta.columns = meta.columns.str.lower()\n",
    "cols = meta.columns\n",
    "file_cols = ['subject_id', 'file']\n",
    "face_cols = cols[cols.str.startswith('face')].tolist()\n",
    "x_cols = cols[cols.str.startswith('p') & cols.str.endswith('x')].tolist()\n",
    "y_cols = cols[cols.str.startswith('p') & cols.str.endswith('y')].tolist()\n",
    "faces_df = meta[file_cols + face_cols + x_cols + y_cols]\n",
    "faces_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T13:03:16.787098Z",
     "start_time": "2019-01-05T13:03:16.769891Z"
    }
   },
   "outputs": [],
   "source": [
    "def show(i, ax=None):\n",
    "    global faces_df, DATA\n",
    "    r = faces_df.loc[i]\n",
    "    img = imread(DATA/r.file)\n",
    "    x_pts = [r[k] for k in r.keys() if k[0] == 'p' and k[-1] == 'x']\n",
    "    y_pts = [r[k] for k in r.keys() if k[0] == 'p' and k[-1] == 'y']\n",
    "    if ax is None:\n",
    "        f, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "    rc = Rectangle(xy=(r.face_x, r.face_y), \n",
    "                   width=r.face_width, height=r.face_height,\n",
    "                   edgecolor='red', fill=False, lw=5)\n",
    "    ax.imshow(img)\n",
    "    ax.scatter(x_pts, y_pts, edgecolor='white', color='lightgreen', alpha=0.8)    \n",
    "    ax.add_patch(rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T13:03:17.211299Z",
     "start_time": "2019-01-05T13:03:16.788052Z"
    }
   },
   "outputs": [],
   "source": [
    "show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T13:03:17.234177Z",
     "start_time": "2019-01-05T13:03:17.213175Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_grid(n=3, figsize=(10, 10)):\n",
    "    global faces_df\n",
    "    f, axes = plt.subplots(n, n, figsize=figsize)\n",
    "    indicies = np.random.choice(len(faces_df), n ** 2, replace=False)\n",
    "    for i, ax in zip(indicies, axes.flat):\n",
    "        show(i, ax=ax)\n",
    "        ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T13:03:17.879754Z",
     "start_time": "2019-01-05T13:03:17.236023Z"
    }
   },
   "outputs": [],
   "source": [
    "show_grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, it seems that each sample includes (at least) one human in various poses with various backgrounds. Therefore, our first goal is to convert this dataset into a more suitable format before we processed with training the model. The most straightforward way to do so is to _crop_ the faces only and save them into smaller files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T13:03:17.898217Z",
     "start_time": "2019-01-05T13:03:17.881816Z"
    }
   },
   "outputs": [],
   "source": [
    "def split(target):\n",
    "    return target[:NUM_LANDMARKS//2], target[NUM_LANDMARKS//2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T13:03:17.914233Z",
     "start_time": "2019-01-05T13:03:17.899271Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_dataset_item(info, root):\n",
    "    \"\"\"Creates a dictionary with face and landmarks coordinates from data frame record.\"\"\"\n",
    "    \n",
    "    return {\n",
    "        'subject_id': info.subject_id,\n",
    "        'image_path': str(root/info.file),\n",
    "        'x_pos': [info[k] for k in info.keys() if k[0] == 'p' and k[-1] == 'x'],\n",
    "        'y_pos': [info[k] for k in info.keys() if k[0] == 'p' and k[-1] == 'y'],\n",
    "        'face': (info.face_x, info.face_y, info.face_width, info.face_height)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T13:03:45.038446Z",
     "start_time": "2019-01-05T13:03:17.915231Z"
    }
   },
   "outputs": [],
   "source": [
    "items = [create_dataset_item(record, DATA) for _, record in meta.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T13:03:45.058440Z",
     "start_time": "2019-01-05T13:03:45.039689Z"
    }
   },
   "outputs": [],
   "source": [
    "trn_idx, val_idx = train_test_split(np.arange(len(items)), test_size=0.1, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T13:03:45.085422Z",
     "start_time": "2019-01-05T13:03:45.059484Z"
    }
   },
   "outputs": [],
   "source": [
    "train = np.array(items)[trn_idx].tolist()\n",
    "valid = np.array(items)[val_idx].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T13:03:45.107407Z",
     "start_time": "2019-01-05T13:03:45.088102Z"
    }
   },
   "outputs": [],
   "source": [
    "class FaceLandmarks:\n",
    "    \n",
    "    def __init__(self, items, transforms=None, to_tensors=None):\n",
    "        self.items = items\n",
    "        self.transforms = transforms\n",
    "        self.to_tensors = to_tensors\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        return self._transform(*self.get(item))\n",
    "    \n",
    "    def show(self, item, ax=None, **fig_kwargs):\n",
    "        self._show(*self.get(item), ax=ax, **fig_kwargs)\n",
    "\n",
    "    def show_transformed(self, item, ax=None, **fig_kwargs):\n",
    "        self._show(*self._transform(*self.get(item), as_tensors=False), ax=ax, **fig_kwargs)\n",
    "        \n",
    "    def show_random_grid(self, n=4, figsize=(10, 10), transformed=False):\n",
    "        size = len(self.items)\n",
    "        indexes = np.random.choice(size, n*n, replace=False)\n",
    "        f, axes = plt.subplots(n, n, figsize=(10, 10))\n",
    "        show = self.show_transformed if transformed else self.show\n",
    "        for idx, ax in zip(indexes, axes.flat):\n",
    "            show(idx, ax=ax)\n",
    "        \n",
    "    def get(self, item):\n",
    "        record = self.items[item]\n",
    "        img = imread(record['image_path'])\n",
    "        pts = np.array(record['x_pos'] + record['y_pos'], dtype='float32')\n",
    "        return img, pts\n",
    "    \n",
    "    def _show(self, img, pts, ax=None, **fig_kwargs):\n",
    "        if ax is None:\n",
    "            f, ax = plt.subplots(1, 1, **fig_kwargs)\n",
    "        ax.imshow(img.astype(np.uint8))\n",
    "        ax.scatter(*split(pts), color='lightgreen', edgecolor='white', alpha=0.8)\n",
    "        ax.set_axis_off()\n",
    "    \n",
    "    def _transform(self, img, pts, as_tensors=True):\n",
    "        if self.transforms:\n",
    "            for transform in self.transforms:\n",
    "                img, pts = transform(img, pts)\n",
    "        if as_tensors and self.to_tensors is not None:\n",
    "            img, pts = self.to_tensors(img, pts)\n",
    "        return img, pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T13:03:45.120873Z",
     "start_time": "2019-01-05T13:03:45.109529Z"
    }
   },
   "outputs": [],
   "source": [
    "ds = FaceLandmarks(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T13:03:45.271836Z",
     "start_time": "2019-01-05T13:03:45.122182Z"
    }
   },
   "outputs": [],
   "source": [
    "ds.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T13:03:45.300557Z",
     "start_time": "2019-01-05T13:03:45.274381Z"
    }
   },
   "outputs": [],
   "source": [
    "def binomial(p):\n",
    "    return np.random.rand() <= p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T13:03:45.317028Z",
     "start_time": "2019-01-05T13:03:45.301580Z"
    }
   },
   "outputs": [],
   "source": [
    "def rotation_matrix(x, y=None, angle=5):\n",
    "    h, w = x.shape[:2]\n",
    "    minmax = (-angle, angle) if isinstance(angle, int) else angle\n",
    "    a = np.random.uniform(*minmax)\n",
    "    m = cv.getRotationMatrix2D((w/2, h/2), a, 1)\n",
    "    m = np.r_[m, [[0, 0, 1]]]\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T13:03:45.334871Z",
     "start_time": "2019-01-05T13:03:45.318049Z"
    }
   },
   "outputs": [],
   "source": [
    "def shift_matrix(x, y=None, shift=0.01):\n",
    "    h, w = x.shape[:2]\n",
    "    sx, sy = (shift, shift) if isinstance(shift, float) else shift\n",
    "    shift_x = np.random.randint(-w*sx, w*sx)\n",
    "    shift_y = np.random.randint(-h*sy, h*sy)\n",
    "    m = np.float32([\n",
    "        [1, 0, shift_x],\n",
    "        [0, 1, shift_y],\n",
    "        [0, 0, 1]]) \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T13:03:45.351296Z",
     "start_time": "2019-01-05T13:03:45.336169Z"
    }
   },
   "outputs": [],
   "source": [
    "def mirror_matrix(x, y=None, horizontal=True):\n",
    "    h, w = x.shape[:2]\n",
    "    c1, c2 = (-1, 1) if horizontal else (1, -1)\n",
    "    s1, s2 = (w, 0) if horizontal else (0, h)\n",
    "    return np.float32([[c1, 0, s1], [0, c2, s2], [0, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T13:03:45.366948Z",
     "start_time": "2019-01-05T13:03:45.352324Z"
    }
   },
   "outputs": [],
   "source": [
    "def perspective_matrix(x, y=None, percentage=(0.05, 0.12)):\n",
    "    h, w = x.shape[:2]\n",
    "    \n",
    "    def rx(): \n",
    "        return int(w*np.random.uniform(*percentage))\n",
    "    \n",
    "    def ry(): \n",
    "        return int(h*np.random.uniform(*percentage))\n",
    "    \n",
    "    tl = [0   + rx(), 0   + ry()]\n",
    "    tr = [w-1 - rx(), 0   + ry()]\n",
    "    br = [w-1 - rx(), h-1 - ry()]\n",
    "    bl = [0   + rx(), h-1 - ry()]\n",
    "    src = np.float32([tl, tr, br, bl])\n",
    "    dst = np.float32([[0, 0], [w-1, 0], [w-1, h-1], [0, h-1]])\n",
    "    m = cv.getPerspectiveTransform(src, dst)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T13:03:45.384725Z",
     "start_time": "2019-01-05T13:03:45.367931Z"
    }
   },
   "outputs": [],
   "source": [
    "class MatrixAugmentation:\n",
    "    def __init__(self, conf, default_prob=0.5):\n",
    "        augmentations = {\n",
    "            'rotation': rotation_matrix,\n",
    "            'shift': shift_matrix,\n",
    "            'mirror': mirror_matrix,\n",
    "            'perspective': perspective_matrix}\n",
    "        \n",
    "        pipe = []\n",
    "        for params in deepcopy(conf):\n",
    "            name = params.pop('name')\n",
    "            func = augmentations.get(name)\n",
    "            if func is None:\n",
    "                raise ValueError(f'unknown augmentation function: {name}')\n",
    "            p = params.pop('p', default_prob)\n",
    "            pipe.append((p, func, params))\n",
    "\n",
    "        self.pipe = pipe\n",
    "        \n",
    "    def __call__(self, image, target=None):\n",
    "        h, w = image.shape[:2]\n",
    "        \n",
    "        m = np.eye(3)\n",
    "        for p, func, params in self.pipe:\n",
    "            if binomial(p):\n",
    "                m = func(image, target, **params) @ m\n",
    "        \n",
    "        aug_image = cv.warpPerspective(image, m, (w, h))\n",
    "        if target is not None:\n",
    "            new = target.copy()\n",
    "            n = len(target)//2\n",
    "            for i in range(n):\n",
    "                x, y = target[i], target[i + n]\n",
    "                denom = m[2][0]*x + m[2][1]*y + m[2][2]\n",
    "                new[i] = (m[0][0]*x + m[0][1]*y + m[0][2])/denom\n",
    "                new[i + n] = (m[1][0]*x + m[1][1]*y + m[1][2])/denom\n",
    "            target = new\n",
    "            \n",
    "        return aug_image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T13:03:45.401569Z",
     "start_time": "2019-01-05T13:03:45.385793Z"
    }
   },
   "outputs": [],
   "source": [
    "class CropResizeFace:\n",
    "    def __init__(self, size=224, pad=0.05):\n",
    "        self.size = size\n",
    "        self.pad = pad\n",
    "        self.failed = []\n",
    "    \n",
    "    def __call__(self, image, target):\n",
    "        size = self.size\n",
    "        xs, ys = split(target)\n",
    "        x_min, x_max, y_min, y_max = xs.min(), xs.max(), ys.min(), ys.max()\n",
    "        \n",
    "        w, h = x_max - x_min, y_max - y_min\n",
    "        x_pad = w*self.pad\n",
    "        y_pad = h*self.pad\n",
    "        \n",
    "        x_min -= x_pad\n",
    "        x_max += x_pad\n",
    "        y_min -= y_pad\n",
    "        y_max += y_pad\n",
    "        \n",
    "        x_min, y_min = max(0, x_min), max(0, y_min)\n",
    "        x_max, y_max = min(image.shape[1], x_max), min(image.shape[0], y_max), \n",
    "        \n",
    "        cropped = image[int(y_min):int(y_max), int(x_min):int(x_max)]\n",
    "        if 0 in cropped.shape:\n",
    "            self.failed.append((image, target))\n",
    "            cropped = image\n",
    "        else:\n",
    "            xs -= x_min\n",
    "            ys -= y_min\n",
    "        \n",
    "        new_w, new_h = (size, size) if isinstance(size, int) else size\n",
    "        old_h, old_w = cropped.shape[:2]\n",
    "        cropped = cv.resize(cropped, (new_w, new_h))\n",
    "        rx, ry = new_w/old_w, new_h/old_h\n",
    "        xs *= rx\n",
    "        ys *= ry\n",
    "        return cropped, np.r_[xs, ys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T13:03:45.415314Z",
     "start_time": "2019-01-05T13:03:45.402511Z"
    }
   },
   "outputs": [],
   "source": [
    "class AdjustGamma:\n",
    "    def __init__(self, min_gamma=0.5, max_gamma=1.5):\n",
    "        self.minmax = min_gamma, max_gamma\n",
    "    \n",
    "    def __call__(self, image, target=None):\n",
    "        gamma = np.random.uniform(*self.minmax)\n",
    "        inv_gamma = 1.0 / gamma\n",
    "        table = np.array([\n",
    "          ((i / 255.0) ** inv_gamma) * 255\n",
    "          for i in np.arange(0, 256)])\n",
    "        adjusted = cv.LUT(\n",
    "            image.astype(np.uint8), \n",
    "            table.astype(np.uint8))\n",
    "        return adjusted.astype(np.float32), target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T13:03:45.427890Z",
     "start_time": "2019-01-05T13:03:45.416234Z"
    }
   },
   "outputs": [],
   "source": [
    "ds.transforms = [\n",
    "    MatrixAugmentation([\n",
    "        {'name': 'rotation', 'angle': 10},\n",
    "        {'name': 'mirror'},\n",
    "        {'name': 'perspective', 'percentage': (0.075, 0.012)}\n",
    "    ]),\n",
    "    CropResizeFace(pad=0.15),\n",
    "    AdjustGamma(min_gamma=0.7)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Images Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T13:03:45.439939Z",
     "start_time": "2019-01-05T13:03:45.428834Z"
    }
   },
   "outputs": [],
   "source": [
    "IMAGENET_STATS = (0.485, 0.456, 0.406), (0.229, 0.224, 0.225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T13:03:45.451939Z",
     "start_time": "2019-01-05T13:03:45.440857Z"
    }
   },
   "outputs": [],
   "source": [
    "def as_is(xs, ys, w, h):\n",
    "    return xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T13:03:45.464176Z",
     "start_time": "2019-01-05T13:03:45.452852Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_centered(xs, ys, w, h):\n",
    "    return 2*xs/w - 1, 2*ys/h - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T13:03:45.477013Z",
     "start_time": "2019-01-05T13:03:45.465309Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_absolute(xs, ys, w, h):\n",
    "    return w*(xs + 1)/2., h*(ys + 1)/2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T13:03:45.489756Z",
     "start_time": "2019-01-05T13:03:45.477974Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_np(t):\n",
    "    return t.cpu().detach().contiguous().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T13:03:45.507103Z",
     "start_time": "2019-01-05T13:03:45.490754Z"
    }
   },
   "outputs": [],
   "source": [
    "class ToXY:\n",
    "    \"\"\"Converts image and landmarks into tensors of appropriate format.\n",
    "    \n",
    "    Includes inverse transformation to convert training and prediction tensors\n",
    "    back into visualization-suitable format.\n",
    "    \"\"\"\n",
    "    def __init__(self, stats=None, y_rescale=True):\n",
    "        self.stats = stats\n",
    "        self.y_rescale = y_rescale\n",
    "        \n",
    "    def __call__(self, image, points):\n",
    "        return self.transform(image, points)\n",
    "    \n",
    "    def transform(self, image, points):\n",
    "        if self.y_rescale:\n",
    "            xs, ys = split(points)\n",
    "            h, w = image.shape[:2]\n",
    "            points = np.r_[to_centered(xs, ys, w, h)]\n",
    "        t_img = to_tensor(image.astype(np.uint8))\n",
    "        t_pts = torch.tensor(points, dtype=t_img.dtype)\n",
    "        if self.stats is not None:\n",
    "            t_img = normalize(t_img, *self.stats)\n",
    "        return t_img, t_pts\n",
    "    \n",
    "    def inverse(self, t_image, t_points):\n",
    "        np_img, np_pts = [to_np(t) for t in (t_image, t_points)]\n",
    "        np_img = np_img.transpose(1, 2, 0)\n",
    "        np_pts = np_pts.flatten()\n",
    "        if self.y_rescale:\n",
    "            h, w = np_img.shape[:2]\n",
    "            xs, ys = to_absolute(*split(np_pts), w, h)\n",
    "            np_pts = np.r_[xs, ys]\n",
    "        if self.stats is not None:\n",
    "            mean, std = self.stats\n",
    "            np_img *= np.array(std)\n",
    "            np_img += np.array(mean)\n",
    "        np_img *= 255\n",
    "        np_img = np_img.astype(np.uint8)\n",
    "        return np_img, np_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T13:03:45.519303Z",
     "start_time": "2019-01-05T13:03:45.508216Z"
    }
   },
   "outputs": [],
   "source": [
    "# class WingLoss(nn.Module):\n",
    "#     def __init__(self, w=10, eps=2):\n",
    "#         super().__init__()\n",
    "#         self.w = w\n",
    "#         self.eps = eps\n",
    "#         self.c = w - w*np.log(1 + w/eps)\n",
    "        \n",
    "#     def forward(self, x, y):\n",
    "#         d = (x - y).abs()\n",
    "#         lt, gt = d < self.w, d >= self.w\n",
    "#         d[lt] = self.w*(1 + d[lt].div(self.eps)).log()\n",
    "#         d[gt] = d[gt] - self.c\n",
    "#         return d.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds = FaceLandmarks(\n",
    "    items=train, \n",
    "    transforms=[\n",
    "        MatrixAugmentation([\n",
    "            {'name': 'rotation', 'angle': 10},\n",
    "            {'name': 'mirror'},\n",
    "            {'name': 'perspective', 'percentage': (0.075, 0.012)}\n",
    "        ]),\n",
    "        CropResizeFace(pad=0.15),\n",
    "        AdjustGamma(min_gamma=0.7)\n",
    "    ], \n",
    "    to_tensors=ToXY(IMAGENET_STATS))\n",
    "\n",
    "val_ds = FaceLandmarks(\n",
    "    items=valid, \n",
    "    transforms=[CropResizeFace(pad=0.15)], \n",
    "    to_tensors=ToXY(IMAGENET_STATS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds.show_random_grid(5, transformed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_landmarks(model, opt, data, epochs=1, batch_size=1024, loss=F.mse_loss):\n",
    "    trn_ds, val_ds = data\n",
    "    phases = make_phases(trn_ds, val_ds, batch_size=batch_size, num_workers=12)\n",
    "    schedule = OneCycleSchedule(len(phases[0].loader) * epochs)\n",
    "    callbacks = C.CallbacksGroup([\n",
    "        C.RollingLoss(),\n",
    "        C.StreamLogger(),\n",
    "        C.ProgressBar(),\n",
    "        C.History(),\n",
    "        C.Scheduler(schedule=schedule,\n",
    "                    mode='batch',\n",
    "                    params_conf=[{'name': 'lr'},\n",
    "                                 {'name': 'weight_decay', 'inverse': True}])])\n",
    "    return loop.train(model, opt, phases, callbacks, epochs, defaults.device, F.mse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classname(obj):\n",
    "    return obj.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(model):\n",
    "    def init(m):\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            nn.init.kaiming_normal_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            nn.init.kaiming_normal_(m.weight)\n",
    "            nn.init.zeros_(m.bias)\n",
    "        elif classname(m).startswith('BatchNorm'):\n",
    "            nn.init.constant_(m.weight, 1)\n",
    "            nn.init.constant_(m.bias, 1e-6)\n",
    "        for child in m.children():\n",
    "            init(child)\n",
    "    init(model.top)\n",
    "    last_linear = model.top[-2]\n",
    "    nn.init.kaiming_normal_(last_linear.weight, nonlinearity='tanh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier(NUM_LANDMARKS, top=[512, 512, 512, 256], activ=nn.Tanh())\n",
    "model.freeze_backbone(True)\n",
    "init_weights(model)\n",
    "opt = AdamW(model.parameters(), lr=5e-2, weight_decay=1e-3)\n",
    "result = train_landmarks(model, opt, (trn_ds, val_ds), epochs=50, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'best_20_epochs.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T14:03:47.716349Z",
     "start_time": "2019-01-05T14:03:47.596330Z"
    }
   },
   "outputs": [],
   "source": [
    "_ = plt.plot(callbacks['scheduler'].parameter_history('lr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T12:26:12.953453Z",
     "start_time": "2019-01-04T12:26:12.865967Z"
    }
   },
   "outputs": [],
   "source": [
    "model = torch.load('best_20_epochs.model')\n",
    "model.freeze_backbone(freeze=False)\n",
    "opt = AdamW([\n",
    "    {'params': model.backbone.parameters(), 'lr': 1e-4, 'weight_decay': 1e-5},\n",
    "    {'params': model.top.parameters(), 'lr': 1e-3, 'weight_decay': 1e-3}\n",
    "])\n",
    "loop.train(model, opt, phases, callbacks, epochs, defaults.device, F.mse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T14:04:06.420034Z",
     "start_time": "2019-01-05T14:04:06.091964Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_img, test_pts = val_ds[14]\n",
    "pred = model(test_img[None].to(defaults.device))\n",
    "np_img, np_pts = val_ds.to_tensors.inverse(test_img, pred)\n",
    "plt.imshow(np_img)\n",
    "plt.scatter(*split(np_pts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# No-Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T11:20:57.879548Z",
     "start_time": "2019-01-05T11:20:57.845030Z"
    }
   },
   "outputs": [],
   "source": [
    "def conv(ni, no, kernel, stride, groups=1, lrn=False, bn=False, pool=None, activ='prelu'):\n",
    "    layers = [nn.Conv2d(ni, no, kernel, stride, groups=groups)]\n",
    "    activation = {\n",
    "        'relu': nn.ReLU(inplace=True),\n",
    "        'prelu': nn.PReLU(),\n",
    "        'linear': None\n",
    "    }[activ]\n",
    "    if activation is not None:\n",
    "        layers += [nn.PReLU()]\n",
    "    if lrn:\n",
    "        layers.append(nn.LocalResponseNorm(2))\n",
    "    elif bn:\n",
    "        layers.append(nn.BatchNorm2d(no))\n",
    "    if pool is not None:\n",
    "        layers.append(nn.MaxPool2d(*pool))\n",
    "    return layers\n",
    "\n",
    "\n",
    "def fc(ni, no, bn=True, activ='linear', dropout=None):\n",
    "    layers = [nn.Linear(ni, no)]\n",
    "    if bn:\n",
    "        layers.append(nn.BatchNorm1d(no))\n",
    "    if activ is not None:\n",
    "        activation = {\n",
    "            'relu': nn.ReLU(inplace=True),\n",
    "            'prelu': nn.PReLU(),\n",
    "            'linear': None\n",
    "        }[activ]\n",
    "        if activation is not None:\n",
    "            layers.append(activation)\n",
    "    if dropout is not None:\n",
    "        layers.append(nn.Dropout(dropout))\n",
    "    return layers\n",
    "\n",
    "\n",
    "class InitShapeEstimator(nn.Module):\n",
    "    \"\"\"Network to predict initial shape S(0) of landmarks.\n",
    "    \n",
    "    Convolution layer C(n, k, g, s):\n",
    "        n = kernel number\n",
    "        k = kernel siznn.Sequential   g = group number\n",
    "        s = stride\n",
    "    \n",
    "    Pooling layer P(k, s):\n",
    "        k = kernel size\n",
    "        s = stride\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(\n",
    "            conv(3, 24, 11, 4, lrn=True, pool=(3, 2)) +\n",
    "            conv(24, 64, 5, 1, lrn=True, pool=(3, 2), groups=2) +\n",
    "            conv(64, 196, 3, 1) +\n",
    "            conv(196, 196, 3, 1, groups=2) +\n",
    "            conv(196, 96, 3, 1, groups=2) +\n",
    "            [Flatten()] + \n",
    "            fc(1536, 1024, bn=False, activ='prelu', dropout=0.25) +\n",
    "            fc(1024, 1024, bn=False, activ='prelu', dropout=0.25) +\n",
    "            fc(1024, NUM_LANDMARKS, bn=False)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "def generate_patches(landmarks, image):\n",
    "    pass\n",
    "\n",
    "\n",
    "def generate_patch(x, y, w, h, image):\n",
    "    patch = torch.tensor(3, h, w, type=image.type())\n",
    "    for q in range(h):\n",
    "        for p in range(w):\n",
    "            yq = y + q - (h - 1)/2\n",
    "            xp = x + p - (w - 1)/2\n",
    "            xd = 1 - (xp - math.floor(xp))\n",
    "            xu = 1 - (math.ceil(xp) - xp)\n",
    "            yd = 1 - (yp - math.floor(yp))\n",
    "            yu = 1 - (math.ceil(yq) - yq)\n",
    "            patch[:, q, p] = (\n",
    "                image[:, math.floor(yq), math.floor(xp)]*yd*xd + \n",
    "                image[:, math.floor(yq),  math.ceil(xp)]*yd*xu +\n",
    "                image[:,  math.ceil(yq), math.floor(xp)]*yu*xd +\n",
    "                image[:,  math.ceil(yq),  math.ceil(xp)]*yu*xu\n",
    "            )\n",
    "    return patch\n",
    "\n",
    "class ResidualModel(nn.Module):\n",
    "    \"\"\"Network to adjust landmark position using input from the previous network.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = conv(3, 16, 6, 2, bn=True, activ='relu')\n",
    "        self.conv2 = conv(16, 16, 3, 1, bn=True, activ='relu')\n",
    "        self.flatten = Flatten()\n",
    "        self.fc1 = fc(128, 128, bn=True, activ='relu')\n",
    "        self.fc2 = fc(128, NUM_LANDMARKS, bn=False)\n",
    "    \n",
    "    def forward(self, s, x):\n",
    "        acts = []\n",
    "        for p in generate_patches(s, x):\n",
    "            p = self.conv1(p)\n",
    "            p = self.conv2(p)\n",
    "            acts.append(p)\n",
    "        x = torch.concat(acts)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T11:20:58.422932Z",
     "start_time": "2019-01-05T11:20:58.382426Z"
    }
   },
   "outputs": [],
   "source": [
    "m = InitShapeEstimator()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
